{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__경사하강법(gradient descent)__\n",
    "\n",
    "---\n",
    "\n",
    "Gradient Descent 방법은 1차 미분계수를 이용해 함수의 최소값을 찾아가는 iterative한 방법이다.\n",
    "\n",
    "---\n",
    "\n",
    "<p>&nbsp;<p>\n",
    "\n",
    "__Gradient Descent 방법의 직관적 의미__\n",
    "\n",
    "---\n",
    "\n",
    "Gradient Descent 방법은 Steepest Descent 방법이라고도 불리는데, 함수 값이 낮아지는 방향으로 독립 변수 값을 변형시켜가면서 최종적으로 최소 함수 값을 갖도록 하는 독립 변수 값을 찾는 방법이다.\n",
    "\n",
    "---\n",
    "\n",
    "<p>&nbsp;<p>\n",
    "\n",
    "__Gradient Descent의 목적과 사용 이유__\n",
    "\n",
    "---\n",
    "\n",
    "Gradient Descent는 함수의 최소값을 찾는 문제에서 활용된다.\n",
    "\n",
    "함수의 최소, 최댓값을 찾는 데에는 미분계수가 0인 지점을 찾는 방식이 있는데, 이와 같은 방식이 아닌 Gradient Descent를 이용해 함수의 최소값을 찾는 주된 이유는\n",
    "\n",
    "* 실제 분석에서 사용될 함수들은 닫힌 형태(closed form)가 아니거나 함수의 형태가 복잡해(대표적으로 비선형함수) 미분계수와 그 근을 계산하기 어려운 경우가 많고,\n",
    "\n",
    "* 실제 미분계수를 계산하는 과정을 컴퓨터로 구현하는 것에 비해 Gradinet Descent는 컴퓨터로 비교적 쉽게 구현할 수 있기 때문이다.\n",
    "\n",
    "* 데이터 양이 매우 큰 경우 Gradient Descent와 같은 iterative한 방법을 통해 해를 구하면 계산량 측면에서 더 효울적으로 해를 구할 수 있다.\n",
    "\n",
    "---\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "__Graident Descent의 수식 유도__\n",
    "\n",
    "---\n",
    "\n",
    "Gradient Descent는 함수의 기울기(즉, gradient)를 이용해 $x$의 값을 어디로 옮겼을 때 함수가 최소값을 찾는지 알아보는 방법이라고 할 수 있다.\n",
    "\n",
    "기울기 양수라는 것은 $x$값이 커질 수록 함수 값이 커진다는 것을 의미하고, 반대로 기울기가 음수라면 $x$값이 커질 수록 함수 값이 작아진다는 것을 이미한다고 볼 수 있다.\n",
    "\n",
    "또, 기울기의 값이 크다는 것은 가파르다는 것을 의미하기도 하지만, 또 한편으로는 $x$의 위치가 최소값/최댓값에 해당되는 $x$좌표로부터 멀리 떨어져있는 것을 의미하기도 한다.\n",
    "\n",
    "이를 이용해 특정 포인트 $x$에서 $x$가 커질 수록 함수 값이 커지는 중이라면(기울기의 부호는 양수) 음의 방향으로 $x$를 옮겨야 할 것이고,\n",
    "\n",
    "반대로 특정 포인트 $x$에서 $x$가 커질 수록 함수 값이 작아지는 중이라면 (기울기의 부호는 음수) 양의 방향으로 $x$를 옮기면 된다.\n",
    "\n",
    "$$\n",
    "x_{i+1} = x_i - \\text{이동거리 * 기울기의 부호}\n",
    "$$\n",
    "\n",
    "여기서 $x_i$와 $x_{i+1}$은 각각 $i$번째 계산된 $x$의 좌표와 $i+1$번째 계산된 $x$의 좌표를 의미한다.\n",
    "\n",
    "이동거리는 gradient 값을 직접 이용하되, 이동 거리를 적절히 사용자가 조절 할 수 있게 수식을 조정하며 상황에 맞게 이동거리를 맞출 수 있게 한다.\n",
    "\n",
    "이동 거리의 조정 값을 보통 step size라고 부르고 기호는 $a$로 쓸 수 있다.\n",
    "\n",
    "미분 계수 값은 극소값에 가까울 수록 그 값이 작아진다.\n",
    "\n",
    "극대값에 가까울 때도 미분 계수는 작아지기 마련이지만, gradient descent 과정에서 극대값에 머물러 있는 경우는 극히 드물다.\n",
    "\n",
    "따라서, 이동거리에 사용할 값을 gradient의 크기와 비례하는 factor를 이용하면 현재 $x$의 값이 극소값에서 멀 때는 많이 이동하고, 극소값에 가까워졌을 때는 조금씩 이동할 수 있게 된다.\n",
    "\n",
    "---\n",
    "\n",
    "<p>&nbsp;</p>\n",
    "\n",
    "__경사하강법 수식__\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "최적화하고자 하는 함수 $f(x)$에 대해 다음과 같이 쓸 수 있다.\n",
    "\n",
    "$$\n",
    "x_{i+1} = x_i - \\alpha\\frac{df}{dx}(x_i)\n",
    "$$\n",
    "\n",
    "다변수함수에 대해 확장하면 다음과 같이 쓸 수 있다.\n",
    "\n",
    "$$\n",
    "x_{i+1} = x_i - \\alpha \\nabla f(x_i)\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
